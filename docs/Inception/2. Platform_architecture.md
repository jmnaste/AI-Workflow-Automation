# Platform Architecture — AI Workflow Automation Agency

## Purpose
Establish a clear, concise, and efficient view of the technical architecture supporting the agency’s AI workflow automation platform. The goal is to balance **clarity**, **scalability**, and **maintainability** — keeping the system smart and simple while enabling enterprise-grade reliability.

---

## 1. Architectural Overview
The platform integrates reasoning, automation, and visibility through a clean layered design:

> **Dashboard (Front-Office)** ⇄ **FastAPI + LangGraph Engine (Back-Office)** ⇄ **Data Stores (Memory & State)** ⇄ **n8n / Integrations (Ops Layer)**

Each layer serves a distinct purpose yet interacts fluidly via well-defined interfaces.

---

## 2. Component Roles
| Layer | Component | Role |
|-------|------------|------|
| **Front-Office** | **Dashboard (Streamlit / React)** | Visualizes results, KPIs, and human-in-the-loop interactions. Enables clients to understand automation impact. |
| **Core Engine** | **FastAPI** | Exposes APIs, orchestrates LangGraph executions, manages user requests, and enforces policies. |
| | **LangGraph** | Executes cognitive workflows (plan → retrieve → decide → act → reflect). Manages reasoning, state, and agent coordination. |
| **Memory Layer** | **Postgres + PGVector** | Stores persistent data, embeddings, workflow states, and context retrieval for RAG operations. |
| **Integration Layer** | **n8n / Custom Connectors** | Handles SaaS integration, triggers, OAuth authentication, and scheduled automations. Serves as operational plumbing, not client interface. |
| **Observability** | **Workflow Run Management + Telemetry (OTEL / Prometheus / Grafana)** | Makes workflow runs, states, and diagnostics visible (run list, state timelines, retries, failure reasons, HITL decisions); telemetry supports analysis and tuning. |
| **Storage** | **S3 / MinIO** | Stores large artifacts such as documents, logs, or AI-generated outputs. |

---

## 3. Data Flow (Simplified)
1. **Trigger:** External event (from n8n, API call, or dashboard input).
2. **Processing:** FastAPI routes to LangGraph for reasoning and execution.
3. **Context Retrieval:** LangGraph queries PGVector for relevant context or documents.
4. **AI Action:** LangGraph performs reasoning, tool calls, and decision loops.
5. **Persistence:** Results and metrics stored in Postgres and S3.
6. **Visualization:** Dashboard renders metrics, KPIs, and outcomes in real time.

---

## 4. Key Design Principles
- **Separation of Concerns:** Each layer has a single, focused responsibility.
- **Workflow-Observable by Design:** Every workflow run and state transition is recorded and viewable; structured logs, traces, and metrics support diagnostics rather than replace run visibility.
- **Secure & Compliant:** Encrypted secrets, masked PII, scoped tokens.
- **Composable:** Reusable primitives, small deployable units.
- **Simple First:** Start with monolithic deployment → evolve to modular microservices as scale demands.

### Client-facing run visibility vs. internal telemetry (SMB focus)
- Primary client view: workflow run management — run list, run detail with state graph, retries, failure reasons, annotations, and HITL decisions.
- Client-facing dashboards also summarize business outcomes: time-to-feature (time to benefit), effectiveness and quality, staff pressure relief, customer experience, and turnaround time.
- Internal telemetry (latency, traces, token/compute usage) remains available for engineering reliability but is not the centerpiece of client reporting.
- Every workflow connects technical spans and logs to business events so that a single run can be tied to a before/after effectiveness snapshot.

---

### API exposure & access model (non-public)
- Private by default: FastAPI has no public IP. Fronted by an internal load balancer/reverse proxy (Traefik/Nginx) in a private network (VPC/VNet) with security groups.
- Allow-list inbound: Only n8n workers and the front-end UI network segment can reach the API; block the internet and unknown subnets.
- Authentication:
  - UI → API: OIDC Authorization Code + PKCE, short-lived tokens; CORS allow-list to the UI origin only.
  - n8n → API: OIDC Client Credentials or signed service tokens; optionally mutual TLS for service-to-service.
  - Enforce scopes/roles per route (e.g., wrm:read, wrm:write); validate JWTs via JWKS (issuer/audience/expiry).
- Edge hardening at the proxy: TLS + HSTS, rate limiting, header/body size caps, sane timeouts, and Trusted Hosts.
- Discovery reduction: Disable or gate Swagger/Redoc in production; use uniform 401/403/404 responses; keep endpoints predictable but unadvertised (no public docs/DNS).
- Egress/SSRF controls: Outbound allow-list for API calls and tools; block private IP ranges in URL fetches.
- Secrets and config: Vault/KMS-managed secrets; rotate keys; do not log tokens or PII; mask sensitive fields in structured logs.
- Auditability: Emit request IDs, actor identity, scopes, and decision outcomes; monitor anomalies (burst calls, failed auth, scope misuse).

## 5. Versioning & Deployment Strategy
- **Repository:** Monorepo (UI, API, LangGraph, Docs) with semantic versioning.
- **Versioning:** MAJOR.MINOR.PATCH with changelogs and tags per module.
- **Deployment:**
  - Local: Docker Compose.
  - Staging: Cloud containers with tracing enabled.
  - Production: Managed Postgres, object storage, autoscaling APIs.
- **Integration:** n8n communicates with FastAPI endpoints via secure REST calls.

---

## 6. Technology Stack (Summary)
| Domain | Technology |
|---------|-------------|
| Frontend | Streamlit / React / Next.js |
| Backend | FastAPI / LangGraph / Python 3.12 |
| Storage | Postgres / PGVector / MinIO |
| Observability | Workflow Run Management UI + Prometheus / Grafana / OpenTelemetry |
| Integrations | n8n / Webhooks / REST APIs |
| Infrastructure | Docker / Fly.io / Render / Kubernetes (optional) |

> Reporting convention for SMBs: public dashboards show business KPIs first; a secondary tab can expose technical health (latency, errors, costs) for operational transparency when needed.

---

## 7. Glossary of Technical Terms and Acronyms
| Term | Definition |
|------|-------------|
| **AI Workflow** | Sequence combining automation and reasoning to perform tasks autonomously. |
| **FastAPI** | A lightweight, high-performance Python framework for APIs. |
| **LangGraph** | Python framework for agentic graph-based workflows and cognitive orchestration. |
| **n8n** | Open-source workflow automation tool for connecting APIs and services. |
| **RAG (Retrieval-Augmented Generation)** | AI technique for combining retrieval with generation for better factuality. |
| **PGVector** | PostgreSQL extension for storing and querying vector embeddings. |
| **HITL (Human-in-the-Loop)** | Process where humans supervise or correct AI outputs. |
| **PII (Personally Identifiable Information)** | Data that can identify an individual; must be protected. |
| **OTEL (OpenTelemetry)** | Framework for collecting traces, metrics, and logs from applications. |
| **S3 / MinIO** | Object storage systems for files, logs, and model artifacts. |
| **API (Application Programming Interface)** | Communication interface between systems or components. |
| **Observability** | Workflow run management first (runs, states, diagnostics), supported by metrics, logs, and traces for analysis. |
| **Workflow Run Management** | UI and APIs that expose run list, state transitions, retries, failure reasons, annotations, and HITL decisions. |
| **Monorepo** | Single repository housing multiple components (UI, API, docs). |
| **Microservice** | Independent service performing one function, communicating via APIs. |
| **Docker Compose** | Tool to define and run multi-container applications locally. |
| **Semantic Versioning (SemVer)** | Standard for versioning software (MAJOR.MINOR.PATCH). |
| **Telemetry** | Automated collection of performance and usage data. |
| **Vector Embedding** | Numerical representation of text enabling semantic search. |

---

### Summary
This document defines a **lean, modular, and observable architecture** where each component has a clear role — ensuring that the agency’s automation systems are robust, maintainable, and easily demonstrated to clients through real data and dashboards.